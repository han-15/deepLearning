{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第五次课后练习题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题重述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import approx_fprime\n",
    "import numpy as np\n",
    "\n",
    "# 相关数据\n",
    "t = np.array([4.0000, 2.0000, 1.0000, 0.5000, 0.2500, 0.1670, 0.1250,\n",
    "              0.1000, 0.0833, 0.0714, 0.0625])\n",
    "y = np.array([0.1957, 0.1947, 0.1735, 0.1600, 0.0844, 0.0627, 0.0456,\n",
    "              0.0342, 0.0323, 0.0235, 0.0246])\n",
    "# 目标函数\n",
    "def f(x):\n",
    "    x1, x2, x3, x4 = x\n",
    "    return np.sum((x1 * (t**2 + x2*t)) / (t**2 + x3*t + x4) - y)**2\n",
    "\n",
    "def f_1(x):\n",
    "    x1, x2, x3, x4 = x\n",
    "    return y - x1 * (t**2 + x2 * t) / (t**2 + x3 * t + x4)\n",
    "\n",
    "# 梯度函数\n",
    "def g(x):\n",
    "    eps = 1e-8\n",
    "    grad = np.zeros_like(x)\n",
    "    for i in range(len(x)):\n",
    "        x1 = np.copy(x)\n",
    "        x2 = np.copy(x)\n",
    "        x1[i] += eps\n",
    "        x2[i] -= eps\n",
    "        grad[i] = (f(x1) - f(x2)) / (2 * eps)\n",
    "    return grad\n",
    "# 黑塞矩阵\n",
    "def G(x, h=1e-5):\n",
    "    n = len(x)\n",
    "    H = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            x_ijp = np.array(x, dtype=float)\n",
    "            x_ijp[i] += h\n",
    "            x_ijp[j] += h\n",
    "            x_ip = np.array(x, dtype=float)\n",
    "            x_ip[i] += h\n",
    "            x_jp = np.array(x, dtype=float)\n",
    "            x_jp[j] += h\n",
    "            x_orig = np.array(x, dtype=float)\n",
    "            H[i, j] = (f(x_ijp) - f(x_ip) - f(x_jp) + f(x_orig)) / (h**2)\n",
    "    return H\n",
    "# 雅可比矩阵\n",
    "def J(x, t = t):\n",
    "    x1, x2, x3, x4 = x\n",
    "    J = np.zeros((len(t), len(x)))\n",
    "    for i, t in enumerate(t):\n",
    "        d1 = (t**2 + x2 * t) / (t**2 + x3 * t + x4)\n",
    "        d2 = x1 * t / (t**2 + x3 * t + x4)\n",
    "        d3 = -x1 * (t**2 + x2 * t) * t / (t**2 + x3 * t + x4)**2\n",
    "        d4 = -x1 * (t**2 + x2 * t) / (t**2 + x3 * t + x4)**2\n",
    "        J[i, :] = [-d1, -d2, -d3, -d4]\n",
    "    return J\n",
    "\n",
    "x0 = [0.2, 0.2, 0.1, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最速下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优解: [0.18067445 0.19332725 0.10365823 0.11497046] \n",
      " 最小值: 4.567515238711441e-15 \n",
      " 迭代次数: 14 \n",
      " 计算时间: 0.02473306655883789\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def Armijo(f, g, xk, dk, alpha = 1, sigma = 0.1, beta = 0.5):\n",
    "    while f(xk + alpha * dk) > f(xk) + sigma * alpha * np.dot(dk, g(xk)):\n",
    "        alpha *= beta\n",
    "    return alpha\n",
    "\n",
    "def SDmethod(f, g, x0, tol = 1e-6):\n",
    "    start = time.time()\n",
    "    xk = x0\n",
    "    items = 0\n",
    "    while np.linalg.norm(g(xk)) >= tol:\n",
    "        dk = - g(xk)\n",
    "        alpha = Armijo(f, g, xk, dk)\n",
    "        xk += alpha * dk\n",
    "        items += 1\n",
    "    end = time.time()\n",
    "    return xk, f(xk), items, end - start\n",
    "\n",
    "\n",
    "x_min, f_min, items, time_cost = SDmethod(f, g, x0)\n",
    "print(f\"最优解:\",x_min,'\\n',\"最小值:\",f_min,'\\n',\"迭代次数:\",items,'\\n',\"计算时间:\",time_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 牛顿法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优解: [ 0.16861388  0.1264594  -0.00553715  0.08761418]\n",
      "最小值: 4.102219949098878e-20\n",
      "迭代次数: 3\n",
      "计算时间: 0.005000114440917969\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def NewtonMethod(f, g, G, x0, tol=1e-6):\n",
    "    start = time.time()\n",
    "    xk = x0\n",
    "    items = 0\n",
    "    while np.linalg.norm(g(xk)) >= tol:\n",
    "        try:\n",
    "            # 尝试计算G(xk)的逆\n",
    "            G_inv = np.linalg.inv(G(xk))\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"G(xk) is singular, switching to steepest descent method.\")\n",
    "            return SDmethod(f, g, xk)  \n",
    "\n",
    "        # 更新xk\n",
    "        xk -= G_inv.dot(g(xk))\n",
    "        items += 1\n",
    "\n",
    "    end = time.time()\n",
    "    return xk, f(xk), items, end - start\n",
    "\n",
    "# 调用NewtonMethod函数\n",
    "x_min, f_min, items, time_cost = NewtonMethod(f, g, G, x0)\n",
    "print(f\"最优解: {x_min}\\n最小值: {f_min}\\n迭代次数: {items}\\n计算时间: {time_cost}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 阻尼牛顿法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优解: [ 0.16861388  0.1264594  -0.00553714  0.08761418]\n",
      "最小值: 4.1021936681749444e-20\n",
      "迭代次数: 3\n",
      "计算时间: 0.014790534973144531\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def DampedNewtonMethod(f, g, G, x0, tol=1e-5):\n",
    "    start = time.time()\n",
    "    xk = x0\n",
    "    items = 0\n",
    "    while np.linalg.norm(g(xk)) >= tol:\n",
    "        Gk = G(xk)\n",
    "        gk = g(xk)\n",
    "\n",
    "        if np.all(np.linalg.eigvals(Gk) <= 0):\n",
    "            print(\"Matrix G(xk) is not positive definite, switching to steepest descent method.\")\n",
    "            return SDmethod(f, g, xk) \n",
    "\n",
    "        try:\n",
    "            dk = -np.linalg.solve(Gk, gk) \n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Matrix G(xk) is singular, switching to steepest descent method.\")\n",
    "            return SDmethod(f, g, xk)\n",
    "\n",
    "        alpha = Armijo(f, g, xk, dk)  \n",
    "        xk += alpha * dk\n",
    "        items += 1\n",
    "\n",
    "    end = time.time()\n",
    "    return xk, f(xk), items, end - start\n",
    "\n",
    "# 调用DampedNewtonMethod函数\n",
    "x_min, f_min, items, time_cost = DampedNewtonMethod(f, g, G, x0)\n",
    "print(f\"最优解: {x_min}\\n最小值: {f_min}\\n迭代次数: {items}\\n计算时间: {time_cost}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拟牛顿法 \n",
    "#### (这里采用BFGS方法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优解: [0.17988071 0.19365835 0.10341633 0.11357361]\n",
      "最小值: 4.003777718663273e-14\n",
      "迭代次数: 7\n",
      "计算时间: 0.013330221176147461\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def BFGSmethod(f, g, x0, tol=1e-5):\n",
    "    start = time.time()\n",
    "    n = len(x0)\n",
    "    xk = x0\n",
    "    B = np.eye(n)  # 初始化黑塞逆矩阵为单位阵\n",
    "    items = 0  # 初始化迭代次数计数器\n",
    "    while np.linalg.norm(g(xk)) >= tol:\n",
    "        grad = g(xk)\n",
    "        dk = -np.dot(B, grad)\n",
    "        alpha = Armijo(f, g, xk, dk)  \n",
    "        xk += alpha * dk\n",
    "        items += 1\n",
    "        \n",
    "        s = alpha * dk\n",
    "        y = g(xk) - grad\n",
    "        Bs = np.dot(B, s)\n",
    "        Bs_dot_s = np.dot(Bs, s)\n",
    "        if np.abs(Bs_dot_s) > 1e-10:  \n",
    "            B += np.outer(y, y) / np.dot(y, s) - np.outer(Bs, Bs) / Bs_dot_s\n",
    "    \n",
    "    end = time.time()\n",
    "    return xk, f(xk), items, end - start\n",
    "\n",
    "x_min, f_min, items, time_cost = BFGSmethod(f, g, x0)\n",
    "print(f\"最优解: {x_min}\\n最小值: {f_min}\\n迭代次数: {items}\\n计算时间: {time_cost}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共轭梯度法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优解: [0.26449945 0.14643722 0.13821816 0.31970571]\n",
      "最小值: 4.403497895091725e-16\n",
      "迭代次数: 16\n",
      "计算时间: 0.04056906700134277\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def Conjugate_Gradient(f, g, x0, method='HS', max_iter=10000, tol=1e-6):\n",
    "    start = time.time()\n",
    "    xk = x0\n",
    "    grad = g(xk)\n",
    "    dk = -grad\n",
    "    items = 0\n",
    "    beta_func = {\n",
    "        'HS': lambda g_next, g, dk: np.dot(g_next, g_next - g) / np.dot(dk, g_next - g),\n",
    "        'PRP': lambda g_next, g: np.dot(g_next, g_next - g) / np.dot(g, g),\n",
    "        'FR': lambda g_next, g: np.dot(g_next, g_next) / np.dot(g, g),\n",
    "        'CD': lambda g_next, g, dk: -np.dot(g_next, g_next) / np.dot(dk, g),\n",
    "        'DY': lambda g_next, g, dk: np.dot(g_next, g_next - g) / np.dot(dk, g_next - g),\n",
    "        'PRP_plus': lambda g_next, g: max(0, np.dot(g_next, g_next - g) / np.dot(g, g))\n",
    "    }[method]\n",
    "    while np.linalg.norm(grad) >= tol and items < max_iter:\n",
    "        alpha = Armijo(f, g, xk, dk)  # 确保Armijo函数已经正确实现\n",
    "        x_next = xk + alpha * dk\n",
    "        g_next = g(x_next)\n",
    "        beta = beta_func(g_next, grad, dk)\n",
    "        dk = -g_next + beta * dk\n",
    "        xk, grad = x_next, g_next\n",
    "        items += 1\n",
    "    end = time.time()\n",
    "    return xk, f(xk), items, end - start\n",
    "\n",
    "# 调用共轭梯度法\n",
    "x_min, f_min, items, time_cost = Conjugate_Gradient(f, g, x0)\n",
    "print(f\"最优解: {x_min}\\n最小值: {f_min}\\n迭代次数: {items}\\n计算时间: {time_cost}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMF方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优解: [0.19280692 0.19128283 0.12305666 0.13606256]\n",
      "最小值: 7.297756577816817e-06\n",
      "迭代次数: 7\n",
      "计算时间: 0.0\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "def LMFmethod(f, j, x0, max_iter=100, tol=1e-6, lambda_ = 0.01, nu = 2.0):\n",
    "    start = time.time()\n",
    "    xk = np.array(x0)\n",
    "    for items in range(max_iter):\n",
    "        r = f_1(xk)\n",
    "        J = j(xk)\n",
    "        \n",
    "        A = J.T @ J\n",
    "        g = J.T @ r\n",
    "        I = np.eye(len(xk))\n",
    "        \n",
    "        delta = np.linalg.solve(A + lambda_ * I, -g)\n",
    "        \n",
    "        if np.linalg.norm(delta) < tol:\n",
    "            break\n",
    "        \n",
    "        x_new = xk + delta\n",
    "        if np.sum(f_1(x_new)**2) < np.sum(r**2):\n",
    "            xk = x_new\n",
    "            lambda_  /=nu\n",
    "        else:\n",
    "            lambda_ *= nu\n",
    "    end = time.time()\n",
    "    \n",
    "    return xk, f(xk), items, end - start\n",
    "\n",
    "# Using the LMF method\n",
    "x_min, f_min, items, time_cost = LMFmethod(f, J, x0)\n",
    "print(f\"最优解: {x_min}\\n最小值: {f_min}\\n迭代次数: {items}\\n计算时间: {time_cost}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
